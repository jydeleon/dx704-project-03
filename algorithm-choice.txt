The rewards are continuous, non-negative, and bounded with high variance, making an uncertainty-aware algorithm appropriate. Upper Confidence Bound (UCB) is suitable because it handles bounded reward distributions without requiring probabilistic priors, while Îµ-greedy explores randomly and Thompson Sampling relies on reward distribution assumptions that do not hold for this setting.